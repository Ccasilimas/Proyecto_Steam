{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza del dataset Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar librerias y dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import ast\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "database_url = os.getenv('DATABASE_URL')\n",
    "api_key = os.getenv('API_KEY')\n",
    "secret_key = os.getenv('SECRET_KEY')\n",
    "\n",
    "# Abrir y leer el archivo .json.gz\n",
    "\n",
    "with gzip.open(r'C:\\Users\\kcasi\\OneDrive\\Documents\\GitHub\\Proyecto_Steam\\Data\\steam_games.json.gz', 'rt', encoding='utf-8') as file:\n",
    "    data = []\n",
    "    for line in file:\n",
    "        try:\n",
    "            data.append(json.loads(line.strip()))  # Convertir de string a diccionario\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON on line: {line}\\nError: {e}\")\n",
    "\n",
    "# Crear un DataFrame de pandas\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Eliminar filas completamente vacías\n",
    "df.dropna(how='all', inplace=True)\n",
    "\n",
    "# Eliminar filas que tengan NaN en cualquier campo\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Eliminar las columnas especificadas\n",
    "columns_to_drop = ['publisher', 'app_name', 'url', 'reviews_url', 'specs','early_access']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza de Filas duplicadas y nulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con fechas inválidas\n",
    "df = df.dropna(subset=['release_date'])\n",
    "\n",
    "# Eliminar filas duplicadas en 'id'\n",
    "df = df.drop_duplicates(subset='id')\n",
    "\n",
    "# Eliminar las filas con valores nulos en la columna 'release_date'\n",
    "df = df.dropna(subset=['release_date'])\n",
    "\n",
    "df = df.dropna(subset=['title'])\n",
    "\n",
    "# Convertir la columna 'release_date' a formato datetime (si no lo es ya)\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resvisar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegúrate de que la columna sea de tipo string antes de hacer la comparación\n",
    "df['price'] = df['price'].astype(str)\n",
    "\n",
    "# Filtra los valores donde la longitud de los datos en 'price' sea menor o igual a 20 caracteres\n",
    "df_filtrado = df[df['price'].str.len() <= 14]\n",
    "\n",
    "# Si deseas modificar el DataFrame original, puedes reasignarlo\n",
    "df = df_filtrado\n",
    "\n",
    "# Convertimos la columna 'price' a numérica, y donde no pueda convertir, pone un 0\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce').fillna(0)\n",
    "\n",
    "\n",
    "# Si necesitas que 'price' sea entero:\n",
    "df['price'] = df['price'].astype(float)\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "# Muestra el DataFrame sin los datos que tenían más de 20 caracteres\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la lista de valores más comunes\n",
    "valores_mas_comunes = df['developer'].value_counts()\n",
    "\n",
    "# Obtener el segundo valor más repetido\n",
    "segundo_mas_repetido = valores_mas_comunes.index[1]  # El índice [1] es el segundo más repetido\n",
    "frecuencia_segundo_mas_repetido = valores_mas_comunes.iloc[1]  # Obtener la frecuencia del segundo más repetido\n",
    "\n",
    "print(f\"El segundo valor más repetido es: {segundo_mas_repetido} con una frecuencia de {frecuencia_segundo_mas_repetido}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conexión a la base de datos MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Conexión a la base de datos MySQL\n",
    "conexion = mysql.connector.connect(\n",
    "    host=os.getenv('DB_HOST'),\n",
    "    port=os.getenv('DB_PORT'),\n",
    "    user=os.getenv('DB_USER'),\n",
    "    password=os.getenv('DB_PASSWORD'),\n",
    "    database=os.getenv('DB_DATABASE')\n",
    ")\n",
    "\n",
    "# Crear cursor\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Crear la tabla si no existe\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS games (\n",
    "    id INT PRIMARY KEY,\n",
    "    title VARCHAR(255),\n",
    "    developer VARCHAR(255),\n",
    "    release_date DATE,\n",
    "    genres JSON,\n",
    "    tags JSON,\n",
    "    price VARCHAR(20)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "# Definir el tamaño del bloque\n",
    "block_size = 1000  # Cambia esto según tus necesidades\n",
    "\n",
    "# Insertar datos del DataFrame en la tabla en bloques\n",
    "for start in range(0, len(df), block_size):\n",
    "    end = start + block_size\n",
    "    chunk = df[start:end]  # Obtén el bloque de datos\n",
    "\n",
    "    # Crear la sentencia de inserción\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO games (id, title, developer, release_date, genres, tags, price)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s,%s)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ejecutar inserciones en bloque\n",
    "    data_to_insert = []\n",
    "    for index, row in chunk.iterrows():\n",
    "        data_to_insert.append((\n",
    "            row['id'],\n",
    "            row['title'],\n",
    "            row['developer'],\n",
    "            row['release_date'],\n",
    "            json.dumps(row['genres']),  # Convertir la lista a JSON\n",
    "            json.dumps(row['tags']),     # Convertir la lista a JSON\n",
    "            row['price']\n",
    "        ))\n",
    "\n",
    "    # Ejecutar la inserción de bloque\n",
    "    cursor.executemany(insert_query, data_to_insert)\n",
    "\n",
    "    # Confirmar los cambios de cada bloque\n",
    "    conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "cursor.close()\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Convertir datos a CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir datos a CSV file\n",
    "df.to_csv('API/Datos/games.csv.gz', index=False, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
